x-base_service: &base_service
    ports:
      - "${WEBUI_PORT:-7860}:7860"
    volumes:
      - &v1 ./data:/data
      - &v2 ./output:/output
    stop_signal: SIGKILL
    tty: true

name: ai-persona-hub-docker


services:
  download:
    build: ./services/download/
    profiles: ["download"]
    volumes:
      - *v1

  auto: &automatic
    <<: *base_service
    profiles: ["auto"]
    build: ./services/AUTOMATIC1111
    image: ai-persona-stable-diffusion # this images will be created once build has been run
    container_name: ai-persona-stable-diffusion-gpu
    environment:
      - CLI_ARGS=--allow-code --medvram --xformers --enable-insecure-extension-access --api --lowram
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']
              capabilities:
                - compute
                - utility
                - gpu
  auto-cpu:
    <<: *automatic
    profiles: ["auto-cpu"]
    deploy: {}
    container_name: ai-persona-stable-diffusion-cpu
    environment:
      - CLI_ARGS=--no-half --precision full --allow-code --enable-insecure-extension-access --api